<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Khushdeep Singh</title>
  
  <meta name="author" content="Khushdeep Singh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Khushdeep Singh</name>
              </p>
              <p>I am currently an Research Engineer at <a href="https://team.inria.fr/chroma/en/">INRIA</a>, Grenoble, France. Previously, 
		      I completed MSc studies with <a href="https://masterschool.eitdigital.eu/programmes/aus/">EIT Digital Master School</a>. 
		      My Major was <a href="https://masterschool.eitdigital.eu/programmes/aus/">Autonomous Systems</a> and minor is Innovation and 
		      Entrepreneurship.
                I completed my masters' thesis at <a href="http://bethgelab.org/">Bethge Lab</a> on 'Improving Robustness in Reinforcement Learning 
		      using self-supervised learning', worked with PhD candidate <a href="https://stes.io/">Steffen Schneider</a>.
              </p>

	      <!------------------------------------------- LINK TO ALL WEBSITES ------------------------------------------------------------------->
	      <p style="text-align:center">
                <a href="mailto:khushdeepvnit@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/khushdeep_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=de&user=Sh5E_NIAAAAJ&view_op=list_works&gmla=AJsN-F5AdGi6VT1MzlLm5SMZVtnAbHVg86C8IxYYjkg1D31DC5MoeEAbue9P4Cjv96LuBK9TFyUioLcvXAJBeWoe5Vv3SpgsVlw4fb_HRvAo4094yh02GBo">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/khushdeepsingh123">LinkedIn</a> &nbsp/&nbsp
		<a href="https://www.researchgate.net/profile/Khushdeep-Singh-Mann">ResearchGate</a> &nbsp/&nbsp
                <a href="https://github.com/ksm26">Github</a>
              </p>
            </td>
            <td style="padding: 2.5%; width: 40%; max-width: 40%;">
		  <a href="images/khushdeep.png">
		    <img style="width: 100%; max-width: 100%; object-fit: cover; object-position: center center;" alt="profile photo" src="images/khushdeep.png" class="hoverZoomLink">
		  </a>
		</td>
          </tr>
	  
	  
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Computer Vision, Deep Learning and Reinforcement Learning. Representative papers are 
		      <span class="highlight">highlighted</span>.
	      </p>
            </td>
          </tr>
        </tbody></table>
	      
        <table style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	
	<!---------------------------------------------- ROS 3D Detection Tracking------------------------------------->
			
	<tr onmouseout="ROS_3D_stop()" onmouseover="ROS_3D_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ROS_3D'><video width=100% height=100% muted autoplay loop>
                  <source src="images/ROS_3D.mp4" type="video/mp4">
		</div>
              <div id='ROS_3D_still'><img src="images/ROS_3D_still.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function ROS_3D_start() {
                      document.getElementById('ROS_3D').style.display = 'inline';
                      document.getElementById('ROS_3D_still').style.display = 'none';
                    }

                function ROS_3D_stop() {
                      document.getElementById('ROS_3D').style.display = 'none';
                      document.getElementById('ROS_3D_still').style.display = 'inline';
                    }
                ROS_3D_stop()
              </script>
            </td>
	  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a href="https://github.com/ksm26/ROS-based-3D-detection-Tracking">
                <papertitle>Real time deployment of 3D object Detection and Tracking module using ROS</papertitle>
              </a>
              <br>
              <strong>Khushdeep Singh Mann</strong>,
              <a href="https://scholar.google.com/citations?user=Q8aj04wAAAAJ&hl=en">Abhishek Tomy</a>,
	      <a href="https://www.davidsgonzalez.com/">David Sierra-Gonzalez</a>,
              <a href="https://scholar.google.com/citations?user=jtnM0c8AAAAJ&hl=en">Christian Laugier</a>

              <a href="https://github.com/ksm26/ROS-based-3D-detection-Tracking">code</a>
              <p></p>
              <p>
              Deployed a real-time 3D object detection and tracking module in ROS, achieving performance at 10FPS for real-time vehicle demonstration
		purposes.
              </p>
            </td>
          </tr>
		
	<!---------------------------------------------- PAPER IV 2022 ------------------------------------------------------->
			
	<tr onmouseout="IV22_stop()" onmouseover="IV22_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='IV22'><video width=100% height=100% muted autoplay loop>
                  <source src="images/IV22.mp4" type="video/mp4">
		</div>
              <div id='IV22_still'><img src="images/IV22_still.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function IV22_start() {
                      document.getElementById('IV22').style.display = 'inline';
                      document.getElementById('IV22_still').style.display = 'none';
                    }

                function IV22_stop() {
                      document.getElementById('IV22').style.display = 'none';
                      document.getElementById('IV22_still').style.display = 'inline';
                    }
                IV22_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a href="https://ksm26.github.io/OccupancyGrid-Predictions/">
                <papertitle>Predicting Future Occupancy Grids in Dynamic Environment with Spatio-Temporal Learning</papertitle>
              </a>
              <br>
              <strong>Khushdeep Singh Mann</strong>,
              <a href="https://scholar.google.com/citations?user=Q8aj04wAAAAJ&hl=en">Abhishek Tomy</a>,
	      <a href="https://anshulpaigwar.github.io/">Anshul Paigwar</a>,
	      <a href="https://sites.google.com/site/arenzaglia/">Alessandro Renzaglia</a>,
              <a href="https://scholar.google.com/citations?user=jtnM0c8AAAAJ&hl=en">Christian Laugier</a>

              <br>
              <em>IEEE Intelligent Vehicles Symposium (IV)</em>, 2022, Aachen, Germany
              <br>
              <a href="https://ksm26.github.io/OccupancyGrid-Predictions/">project page</a> /
              <a href="https://arxiv.org/pdf/2205.03212.pdf">arXiv</a> /
	      <a href="https://www.youtube.com/watch?v=4W7dT-HfQPQ">video</a> /
	      <a href="https://github.com/ksm26/OccupancyGrid-Predictions">code</a>
              <p></p>
              <p>
              We propose a spatio-temporal prediction network pipeline that takes the past information from the environment and semantic labels 
	      separately to predict occupancy for a longer horizon of 3 seconds and in a relatively complex environment.
              </p>
            </td>
          </tr>
				
	  <!----------------------------------------------- PAPER ICRA 2022 ------------------------------------------------------------->  
		
          <tr onmouseout="ICRA22_stop()" onmouseover="ICRA22_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ICRA22'><video width=100% height=100% muted autoplay loop>
                  <source src="images/ICRA22_video.mp4" type="video/mp4">
		</div>
              <div id='ICRA22_still'><img src="images/ICRA22_still.png" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function ICRA22_start() {
                      document.getElementById('ICRA22').style.display = 'inline';
                      document.getElementById('ICRA22_still').style.display = 'none';
                    }

                function ICRA22_stop() {
                      document.getElementById('ICRA22').style.display = 'none';
                      document.getElementById('ICRA22_still').style.display = 'inline';
                }
                ICRA22_stop()
              </script>
            </td>
  
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://abhishek1411.github.io/event-rgb-fusion/">
                <papertitle>Fusing Event-based and RGB camera for Robust Object Detection in Adverse Conditions</papertitle>
              </a>
              <br>
       
              <a href="https://scholar.google.com/citations?user=Q8aj04wAAAAJ&hl=en">Abhishek Tomy</a>,
	      <a href="https://anshulpaigwar.github.io/">Anshul Paigwar</a>,
	      <strong>Khushdeep Singh Mann</strong>,
	      <a href="https://sites.google.com/site/arenzaglia/">Alessandro Renzaglia</a>,
              <a href="https://scholar.google.com/citations?user=jtnM0c8AAAAJ&hl=en">Christian Laugier</a>
              <br>
	
	      <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2022, Philadelphia, United States.
              <br>
              <a href="https://abhishek1411.github.io/event-rgb-fusion/">project page</a> /
              <a href="https://hal.archives-ouvertes.fr/hal-03591717/">paper</a> /
              <a href="https://www.youtube.com/watch?v=2nrqhiiXJwY">video</a> /
              <a href="https://github.com/abhishek1411/event-rgb-fusion">code</a> /
              <a href="https://www.youtube.com/watch?v=xg3ExZV84Yg">presentation</a>
              <p></p>
              <p>We propose a redundant sensor fusion model of event-based and frame-based cameras that is robust to
                    common image
                    corruptions. Our sensor fusion approach is over <strong>30% more robust to corruptions </strong>
                    compared to only frame-based detections and
                    outperforms the only event-based detection.</p>
            </td>
          </tr> 
		
		
		
	<!----------------------------------------------- PAPER ICLR 2021 ------------------------------------------------------------->
	
          <tr onmouseout="ICLR21_stop()" onmouseover="ICLR21_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">     
              <div class="one">
                <div class="two" id='ICLR21'><video width=100% height=100% muted autoplay loop>
                  <img src="images/ICLR21.mp4" type="video/mp4">
		</div>
              <div id='ICLR21_still'><img src="images/ICLR21.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function ICLR21_start() {
                      document.getElementById('ICLR21').style.display = 'inline';
                      document.getElementById('ICLR21_still').style.display = 'none';
                    }

                function ICLR21_stop() {
                      document.getElementById('ICLR21').style.display = 'none';
                      document.getElementById('ICLR21_still').style.display = 'inline';
                }
                ICLR21_stop()
              </script>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://stes.io/iclr2021-ssl-rl/">
                <papertitle>Out-of-distribution generalization of internal models is correlated with reward</papertitle>
              </a>
              <br>
              <strong>Khushdeep Singh Mann</strong>, 
	      <a href="https://stes.io/">Steffen Schneider</a>
              <a href="https://scholar.google.com/citations?user=Cv5lSo0AAAAJ&hl=it">Alberto Chiappa</a>
	      <a href="https://jinhl9.github.io/">Jin Hwa Lee</a>
	      <a href="http://bethgelab.org/">Matthias Bethge</a>
	      <a href="https://www.mathislab.org/">Alexander Mathis</a>
	      <a href="http://www.mackenziemathislab.org/">Mackenzie W. Mathis</a>
              <br>
              <em>ICLR SSL-RL workshop</em>, 2021
              <br>
              <a href="https://stes.io/iclr2021-ssl-rl/">project page</a> /
              <a href="https://openreview.net/pdf?id=hR_TNbCr_nQ">paper</a> /
              <a href="https://stes.io/iclr2021-ssl-rl/ssl-rl-poster.pdf">poster</a> /
	      <a href="https://sslrlworkshop.github.io/">workshop page</a>
              <p> We investigate the behavior of reinforcement learning (RL) agents under morphological distribution shifts. We specifically test 
		      perturbations to popular RL agent‚Äôs morphologies by changing the length and mass of limbs, which in biological settings is a major 
		      challenge (e.g., after injury or during growth).We find that out-of-distribution performance of 
		      self-supervised models is correlated to degradation in reward.</p>
            </td>
          </tr>
		
	  <!----------------------------------------------- PAPER CHAP 2017 ------------------------------------------------------------->
	
          <tr onmouseout="CHAP17_stop()" onmouseover="CHAP17_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='CHAP17'><video width=100% height=125% muted autoplay loop>
                  <source src="images/chap.mp4" type="video/mp4">
		</div>
              <div id='CHAP17_still'><img src="images/chap.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function CHAP17_start() {
                      document.getElementById('CHAP17').style.display = 'inline';
                      document.getElementById('CHAP17_still').style.display = 'none';
                    }

                function CHAP17_stop() {
                      document.getElementById('CHAP17').style.display = 'none';
                      document.getElementById('CHAP17_still').style.display = 'inline';
                }
                CHAP17_stop()
              </script>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://mobile-chap.github.io/Web/">
                <papertitle>An Open-Source Tele-Operated Mobile Manipulator: CHAP V1</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.co.uk/citations?user=Cu4CRG4AAAAJ&hl=en">Guido Bugmann</a>
	      <a href="">Paul Doyle</a>
	      <a href="">Arunaganesan Swaminathan</a>
	      <strong>Khushdeep Singh Mann</strong>
	      <a href="">Paul Doyle</a>
              <a href="">Dominic Cassidy</a>
              <br>
              <em>TAROS</em>, 2017
              <br>
              <a href="https://mobile-chap.github.io/Web/">project page</a> /
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-64107-2_16">paper</a> /
              <a href="https://www.youtube.com/watch?v=-FDXMkB4JsY">video</a> /
	      <a href="https://github.com/Mobile-CHAP/Web">code</a>
              <p>Teleoperated mobile manipulators are of use for disabled people. 
		      The high price of existing devices is a barrier to their diffusion. The paper reports on the first design produced in the 
		      Cheap Arm Project (CHAP) under ¬£2000.</p>
            </td>
          </tr>

          <!----------------------------------------------- PAPER ROBIO 2016 ------------------------------------------------------------->
	
          <tr onmouseout="ROBIO16_stop()" onmouseover="ROBIO16_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ROBIO16'><video width=125% height=100% muted autoplay loop>
                  <source src="images/hand.mp4" type="video/mp4">
		</div>
              <div id='ROBIO16_still'><img src="images/hand.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function ROBIO16_start() {
                      document.getElementById('ROBIO16').style.display = 'inline';
                      document.getElementById('ROBIO16_still').style.display = 'none';
                    }

                function ROBIO16_stop() {
                      document.getElementById('ROBIO16').style.display = 'none';
                      document.getElementById('ROBIO16_still').style.display = 'inline';
                }
                ROBIO16_stop()
              </script>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/7866623">
                <papertitle>Design Analysis and Development of Low Cost Underactuated Robotic Hand</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.com/citations?user=oY5-d8AAAAAJ&hl=en">Parag Khanna</a>
              <strong>Khushdeep Singh Mann</strong>
	      <a href="https://scholar.google.com/citations?user=B9InqKQAAAAJ&hl=en">Shital Chiddarwar</a>
	      <a href="https://scholar.google.com/citations?user=RfarD8wAAAAJ&hl=en">Kishor Bhurchandi</a>
              <br>
              <em>ROBIO</em>, 2016
	      <br>
              <a href="https://ieeexplore.ieee.org/document/7866623">paper</a> /
              <a href="https://www.youtube.com/watch?v=vc7MZVaqRGM">video</a>
              <p>This paper represents the control and driving mechanism of IVLABS Robotic hand, which aims to grab different objects performing various 
		      types of grasps while retaining the resemblance of a human hand; thus it is able to function as a Prosthetic hand. 
		      The paper focuses on the design of hand, that is cost-effective yet imparts maximum functionality by using simple 
		      actuation and using proximity sensors on fingers.</p>

            </td>
          </tr>

        </tbody></table>
	      
	      
    
	      
	<!---------------------------------------------- OTHER PROJECTS ------------------------------------------------------->
	      
        <table style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
        <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Other Projects</heading>
                  <p>
                    
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
		
          <table
            style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
		
	<!---------------------------------------------- AUTONOMOUS WAREHOUSING SYSTEM ------------------------------------------------------->
			
	<tr onmouseout="AWS_stop()" onmouseover="AWS_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='AWS'><video width=100% height=125% muted autoplay loop>
                  <source src="images/AWS.mp4" type="video/mp4">
		</div>
              <div id='AWS_still'><img src="images/AWS_still.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function AWS_start() {
                      document.getElementById('AWS').style.display = 'inline';
                      document.getElementById('AWS_still').style.display = 'none';
                    }

                function AWS_stop() {
                      document.getElementById('AWS').style.display = 'none';
                      document.getElementById('AWS_still').style.display = 'inline';
                    }
                AWS_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a href="https://www.researchgate.net/publication/358472695_Autonomous_Smart_Factory_Assembly_and_Warehousing">
                <papertitle>Autonomous Smart Factory: Assembly and Warehousing</papertitle>
              </a>
              <br>
		    <a>Tor Istvan Stadler Kjets Ãäa</a>,
		    <a>Tim Allen</a>,
		    <a>Sangeetha Reji</a>,
		    <strong>Khushdeep Singh Mann</strong>
              <br>
              <em>Distributed Artificial Intelligence Laboratory (DAI-Labor), TU Berlin</em>, 2019, Berlin, Germany
              <br>
	      <a href="https://www.youtube.com/watch?v=lpXbBDoZZek">video</a> /
              <p></p>
              <p>
              The Scenario explained here includes 
		      a warehouse with a package generator, input and output trays for the packages to move around, and robots to perform the storing 
		      and transportation. The architecture developed in this paper deals with a centralized task planner that deals 
		      with all the packages the agents are transporting and a decentralized path planner inside each agent to create its own path to the 
		      target trays or charging units. </p>
            </td>
          </tr>
		
	<!---------------------------------------------- ACOUSTIC SENSING ------------------------------------------------------->
			
	<tr onmouseout="acoustic_stop()" onmouseover="acoustic_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='acoustic'><video width=100% height=100% muted autoplay loop>
                  <source src="images/acoustic.png" type="video/mp4">
		</div>
              <div id='acoustic'><img src="images/acoustic.png" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function acoustic_start() {
                      document.getElementById('acoustic').style.display = 'inline';
                      document.getElementById('acoustic').style.display = 'none';
                    }

                function acoustic_stop() {
                      document.getElementById('acoustic').style.display = 'none';
                      document.getElementById('acoustic').style.display = 'inline';
                    }
                acoustic_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a <papertitle>Sensitivity of Acoustic sensing to pressure in soft robotic fingers</papertitle>
              </a>
              <br>
		    <strong>Khushdeep Singh Mann</strong>
              <br>
              <em>Robotics and Biology Laboratory (RBO), TU Berlin</em>, 2019, Berlin, Germany
              <br>

              <p></p>
              <p>
              We analyze the influence of pressure on the prediction ability of acoustic sensing technique in soft robotic fingers. 
		      The method uses a single air chamber soft fingers with an embedded speaker and microphone.  </p>
            </td>
          </tr>

	  <!---------------------------------------------- snake robot ------------------------------------------------------->
	  
	  <tr onmouseout="snake_stop()" onmouseover="snake_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='snakevid'><video width=120% height=100% muted autoplay loop>
                  <source src="images/snake.mp4" type="video/mp4">
		</div>
              <div id='snake'><img src="images/snake.png" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function snake_start() {
                      document.getElementById('snakevid').style.display = 'inline';
                      document.getElementById('snake').style.display = 'none';
                    }

                function snake_stop() {
                      document.getElementById('snake').style.display = 'none';
                      document.getElementById('snakevid').style.display = 'inline';
                    }
                snake_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a <papertitle>Design and Control of Snake robot</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.com/citations?user=oY5-d8AAAAAJ&hl=en">Parag Khanna</a>
	      <strong>Khushdeep Singh Mann</strong>
              <br>
              <em>Visvesvaraya National Institute of Technology (VNIT),</em>, 2016, Nagpur, India
              <br>
		<a href="https://www.youtube.com/watch?v=ghq8nj30-pE&t=4s">video</a> 
              <p></p>
              <p> A snake robot capable of doing standard locomotive gaits  </p>
            </td>
          </tr>


	  <!---------------------------------------------- quad robot ------------------------------------------------------->
	  
	  <tr onmouseout="quad_stop()" onmouseover="quad_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='quadvid'><video width=120% height=100% muted autoplay loop>
                  <source src="images/quad.mp4" type="video/mp4">
		</div>
              <div id='quad'><img src="images/quad.png" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function quad_start() {
                      document.getElementById('quadvid').style.display = 'inline';
                      document.getElementById('quad').style.display = 'none';
                    }

                function quad_stop() {
                      document.getElementById('quad').style.display = 'none';
                      document.getElementById('quadvid').style.display = 'inline';
                    }
                quad_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a <papertitle>Design and Control of Quadcopter</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.com/citations?user=oY5-d8AAAAAJ&hl=en">Parag Khanna</a>
	      <strong>Khushdeep Singh Mann</strong>
              <br>
              <em>Visvesvaraya National Institute of Technology (VNIT),</em>, 2015, Nagpur, India
              <br>
		<a href="https://www.youtube.com/watch?v=JtWZkULuiWw">video</a> 
              <p></p>
              <p> A quad copter capable of doing standard maneuvers  </p>
            </td>
          </tr>


<!---------------------------------------------- biped robot ------------------------------------------------------->
	  
	  <tr onmouseout="biped_stop()" onmouseover="biped_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bipedvid'><video width=100% height=125% muted autoplay loop>
                  <source src="images/biped.mp4" type="video/mp4">
		</div>
              <div id='biped'><img src="images/biped.jpg" width=100% height=100%></div>
              </div>
              <script type="text/javascript">
                function biped_start() {
                      document.getElementById('bipedvid').style.display = 'inline';
                      document.getElementById('biped').style.display = 'none';
                    }

                function biped_stop() {
                      document.getElementById('biped').style.display = 'none';
                      document.getElementById('bipedvid').style.display = 'inline';
                    }
                biped_stop()
              </script>
            </td>
		  
	     
		  
            <td style="padding-left:20px;padding-right: 20px; padding-top:10px;padding-bottom: 10px;width:70%;vertical-align:middle">
              <a <papertitle>Design and Control of Biped Robot</papertitle>
              </a>
              <br>
	      <a href="https://scholar.google.com/citations?user=oY5-d8AAAAAJ&hl=en">Parag Khanna</a>
	      <strong>Khushdeep Singh Mann</strong>
	      <a>Akhilesh Patil </a>
              <br>
              <em>Visvesvaraya National Institute of Technology (VNIT),</em>, 2014, Nagpur, India
              <br>
		<a href="https://www.youtube.com/watch?v=WmCKMqNgFoY">video</a> 
              <p></p>
              <p> A 6 DoF biped robot capable of walking </p>
            </td>
          </tr>

	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>,
                just add a link back to my website.
                <strong>Do not</strong> scrape the HTML from the deployed instance of this website at http://jonbarron.info,
                as it includes analytics tags that you do not want on your own website &mdash; use the github code instead.
      
                <br>
                Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
